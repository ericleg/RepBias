{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "constitutional-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "This notebook prepares the raw data for further statistical analyses. Participants with extreme behavior are excluded. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-wagon",
   "metadata": {},
   "source": [
    "### load data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "introductory-label",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of participants: 74\n"
     ]
    }
   ],
   "source": [
    "# set path and load file names\n",
    "path = '../data_empirical_raw/' # \n",
    "fileNames = listdir(path)\n",
    "fileNames = [file for file in fileNames if not file.startswith('meta_') ] # don't load the meta files\n",
    "print('Number of participants: {}'.format(len(fileNames)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract the important information from the raw data files\n",
    "The resulting data includes: participant ID, block no., trial no., time out, used sequence of actions, reaction time, reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "becoming-approach",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this functions loads and prepares data from one participant and returns a panda\n",
    "def prepare_data_participant(fname, path):\n",
    "    \n",
    "    # define columns to use of the raw file\n",
    "    cols = ['sender', 'sender_id', 'move', 'blockN', 'trialN', 'duration','reward', 'moveCount', 'movesTrial'] \n",
    "    # deleted: 'visitedFields', 'points', 'response', 'diff',\n",
    "    \n",
    "    # load data from current participant\n",
    "    df = pd.read_csv(path+fname, header=0, usecols=cols) # read data from csv\n",
    "    \n",
    "    # filter data for relevant rows\n",
    "    filterExperiment = df['sender_id'].str[0:4]=='0_12' # just experiment (not training as well)\n",
    "    filterMoves = df['sender']=='Move' # only moves\n",
    "    filterFeedback = df['sender']=='Feedback' # only feedback with difference and reward (incl bonus)\n",
    "    \n",
    "    # get df with just the feedback rows\n",
    "    dfTrials = df.loc[(filterExperiment) & (filterFeedback), 'trialN':'reward'].reset_index()\n",
    "\n",
    "    # get RT for the whole trial \n",
    "    dfRTs = df['duration'].loc[(filterExperiment) & (filterMoves)].groupby([df['blockN'], df['trialN']], sort=False).sum().rename('RT').reset_index()\n",
    " \n",
    "    dfTrials['RT'] = dfRTs['RT']\n",
    "\n",
    "    # delete useless index column\n",
    "    del dfTrials['index']\n",
    "\n",
    "    return dfTrials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "# loop over all participants\n",
    "for idx, fileName in enumerate(fileNames):\n",
    "    dfParticipant = prepare_data_participant(fileName, path) # get prepared data\n",
    "    dfParticipant['Participant_ID'] = idx # add participant ID\n",
    "    df = pd.concat([df, dfParticipant], ignore_index=True) # concatenate to one big panda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define time out trials and add action sequence IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add indicator column for time out trials (not all four moves completed)\n",
    "df['time_out'] = 0\n",
    "df.loc[df['moveCount']<4, 'time_out'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file with the sequences (IDs)\n",
    "f = open('../data_task/sequences.pkl', 'rb')\n",
    "sequences = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the moves from string into integer (excl. time out trials)\n",
    "df.loc[df['time_out']==0, 'movesTrial'] = df.loc[df['time_out']==0, 'movesTrial'].apply(lambda x: [int(val) for val in x.split(',') ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the sequence IDs\n",
    "df['sequence_ID'] = np.nan\n",
    "df.loc[df['time_out']==0, 'sequence_ID'] = df.loc[df['time_out']==0, 'movesTrial'].apply(lambda row: np.where((sequences == row).all(axis=1))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate DAS proportions to exclude participants with extreme high or low proportions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxDAS = 4 # set the DAS index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the sequences of actions for all valid trials\n",
    "dfSequences = df.loc[df['time_out']==0, ['Participant_ID', 'sequence_ID']]\n",
    "\n",
    "# count how often each participant has used each sequence of\n",
    "dfSequences = dfSequences.groupby('Participant_ID').value_counts().rename('count_sequence').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the proportion of DAS choices\n",
    "nTrialsParticipants = dfSequences['count_sequence'].groupby(dfSequences['Participant_ID']).sum().to_numpy()\n",
    "nDASParticipants = dfSequences.loc[dfSequences['sequence_ID']==idxDAS, 'count_sequence'].to_numpy()\n",
    "pDASParticipants = nDASParticipants/nTrialsParticipants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find participants with $p(\\text{DAS})>90%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pDAS90 = np.where(pDASParticipants<.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print $p(\\text{DAS})$ of the outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.  , 0.99, 0.94, 0.91])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pDASParticipants[np.where(pDASParticipants>.90)].round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exclude outliers from the panda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[df['Participant_ID'].isin(pDAS90[0])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create a new participant ID column without missing IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove old ID column and add new one\n",
    "nTrials = len(df['trialN'].unique())*len(df['blockN'].unique())\n",
    "newIDColumn = np.arange(len(df['Participant_ID'].unique())).repeat(nTrials)\n",
    "df.pop('Participant_ID')\n",
    "df.insert(0, 'Participant_ID', newIDColumn) # insert new ID column at first position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save the resulting panda for further analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data_empirical/data_cleaned.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-canyon",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceramic-geography",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Wed Apr 17 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.6\n",
      "IPython version      : 8.16.1\n",
      "\n",
      "seaborn: 0.13.0\n",
      "pandas : 2.1.1\n",
      "numpy  : 1.25.2\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print date of last changes and version numbers\n",
    "%load_ext watermark\n",
    "\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
