{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load own functions\n",
    "sys.path.append('../') # add path of parent directory to find the functions folder\n",
    "from functions import inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Inference\n",
    "based on MCMC with PyMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load expected rewards of each sequence at each trial\n",
    "trialRewards = pd.read_csv('../data_task/trial_sequence_rewards.csv', header=None)\n",
    "\n",
    "# set sequence ID of DAS\n",
    "IdxDAS = 4\n",
    "\n",
    "# load data (data set including time out trials -> sequence_ID: NaN)\n",
    "dfData = pd.read_csv('../data_empirical/data_cleaned.csv')\n",
    "\n",
    "# save this df (in case there are modifications on the original file to perform descriptive statistics)\n",
    "dfData.to_csv('../inference_data/data_behavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randon Response Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s3090986\\AppData\\Local\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\model\\core.py:1342: RuntimeWarning: invalid value encountered in cast\n",
      "  data = convert_observed_data(data).astype(rv_var.dtype)\n",
      "c:\\Users\\s3090986\\AppData\\Local\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\model\\core.py:1365: ImputationWarning: Data in Y contains missing values and will be automatically imputed from the sampling distribution.\n",
      "  warnings.warn(impute_message, ImputationWarning)\n",
      "Multiprocess sampling (4 chains in 4 jobs)\n",
      "CategoricalGibbsMetropolis: [Y_unobserved]\n",
      "Sampling 4 chains for 1_000 tune and 1_000 draw iterations (4_000 + 4_000 draws total) took 429 seconds.\n",
      "c:\\Users\\s3090986\\AppData\\Local\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\pymc\\pytensorf.py:1055: UserWarning: RNG Variable RandomGeneratorSharedVariable(<Generator(PCG64) at 0x269F0CED540>) has multiple clients. This is likely an inconsistent random graph.\n",
      "  warnings.warn(\n",
      "Sampling: [Y_observed]\n"
     ]
    }
   ],
   "source": [
    "# run inference\n",
    "iDataRandom = inference.inference_random_group(dfData, trialRewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\s3090986\\AppData\\Local\\anaconda3\\envs\\pymc_env\\Lib\\site-packages\\arviz\\stats\\stats.py:803: UserWarning: Estimated shape parameter of Pareto distribution is greater than 0.7 for one or more samples. You should consider using a more robust model, this is because importance sampling is less likely to work well if the marginal posterior and LOO posterior are very different. This is more likely to happen with a non-robust model and highly influential observations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Computed from 4000 posterior samples and 22068 observations log-likelihood matrix.\n",
       "\n",
       "             Estimate       SE\n",
       "deviance_loo 158162.19     0.00\n",
       "p_loo            0.00        -\n",
       "\n",
       "There has been a warning during the calculation. Please check the results.\n",
       "------\n",
       "\n",
       "Pareto k diagnostic values:\n",
       "                         Count   Pct.\n",
       "(-Inf, 0.5]   (good)         0    0.0%\n",
       " (0.5, 0.7]   (ok)           0    0.0%\n",
       "   (0.7, 1]   (bad)          0    0.0%\n",
       "   (1, Inf)   (very bad) 22068  100.0%"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "az.loo(iDataRandom, scale='Deviance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVPRM just non-DAS trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVPRMnonDAS = inference.inference_EVPRMnonDAS_group(dfData, trialRewards.to_numpy(), IdxDAS)\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVPRMnonDAS_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVPRMnonDAS, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVPRM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVPRM = inference.inference_EVPRM_group(dfData, trialRewards.to_numpy(), IdxDAS)\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVPRM_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVPRM, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EVPRM v2\n",
    "Alternative EVPRM with separate repetition bias strength parameters for DAS and all other sequences of actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVPRM_v2 = inference.inference_EVPRM_v2_group(dfData, trialRewards.to_numpy(), IdxDAS)\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVPRM_v2_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVPRM_v2, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVPBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVPBM = inference.inference_EVPBM_group(dfData, trialRewards.to_numpy(), IdxDAS)\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVPBM_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVPBM, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVPM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVPM = inference.inference_EVPM_group(dfData, trialRewards.to_numpy(), IdxDAS)\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVPM_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVPM, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run inference\n",
    "iDataEVM = inference.inference_EVM_group(dfData, trialRewards.to_numpy())\n",
    "\n",
    "# save iData object\n",
    "fname = '../inference_data/posterior_EVM_empirical.pkl'\n",
    "f = open(fname, 'wb')\n",
    "pickle.dump(iDataEVM, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The watermark extension is already loaded. To reload it, use:\n",
      "  %reload_ext watermark\n",
      "Last updated: Thu Feb 08 2024\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.11.6\n",
      "IPython version      : 8.16.1\n",
      "\n",
      "pandas: 2.1.1\n",
      "sys   : 3.11.6 | packaged by conda-forge | (main, Oct  3 2023, 10:29:11) [MSC v.1935 64 bit (AMD64)]\n",
      "numpy : 1.25.2\n",
      "\n",
      "Watermark: 2.4.3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print date of last changes and version numbers\n",
    "%load_ext watermark\n",
    "\n",
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymc_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
